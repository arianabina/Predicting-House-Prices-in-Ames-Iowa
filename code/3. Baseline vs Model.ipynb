{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da5c376-96fa-48c2-b43e-009ede402dbf",
   "metadata": {},
   "source": [
    "## Baseline vs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19b37ba-858c-4e82-a049-aacae6e52748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5425a598-2d9a-4599-be7b-4dd990fdc246",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './clean_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load cleaned and encoded dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./clean_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./clean_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './clean_train.csv'"
     ]
    }
   ],
   "source": [
    "# Load cleaned and encoded dataset\n",
    "train3 = pd.read_csv('./clean_train.csv')\n",
    "test3 = pd.read_csv('./clean_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f55de5-6097-4492-b96e-4ef6b1be0cdd",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041de7c-ff0d-43b4-bd4a-3a0e7716842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "y = train3['SalePrice']\n",
    "X = train3.drop(columns=['SalePrice', 'Unnamed: 0'])  \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f975c70-4b63-4e6d-b3bc-4924367ca72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b25af-116d-4205-aff5-c9aa4762095f",
   "metadata": {},
   "source": [
    "## Scaling The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32db7b-3cfd-4f65-9a15-62231d83bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Define categorical features\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Make copies of the data frames\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7c4b2-1510-41f2-9e1e-4fd440199fe6",
   "metadata": {},
   "source": [
    "## Establishing A Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118e710-e63c-4ef5-8602-567361caa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the \"SalePrice\" feature\n",
    "mean_sale_price = y_train.mean()\n",
    "\n",
    "# Create baseline predictions using the mean\n",
    "baseline_predictions = [mean_sale_price] * len(y_test)\n",
    "\n",
    "# Evaluate the baseline predictions\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "baseline_mse = mean_squared_error(y_test, baseline_predictions)\n",
    "baseline_rmse = baseline_mse ** 0.5\n",
    "\n",
    "print(\"Baseline RMSE:\", baseline_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0cfed4-ef82-4211-92f6-b38716595649",
   "metadata": {},
   "source": [
    "## Fitting Linear, Lasso & Ridge Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b07adb-dd8f-4dcc-afa3-d4d0fe6708a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize models\n",
    "linear_reg_model = LinearRegression()\n",
    "lasso_model = Lasso(alpha=10, max_iter=10000)  \n",
    "ridge_model = Ridge(alpha=10, max_iter=10000)  \n",
    "\n",
    "# Fit models\n",
    "linear_reg_model.fit(X_train_scaled, y_train)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions \n",
    "linear_reg_predictions = linear_reg_model.predict(X_test_scaled)\n",
    "lasso_predictions = lasso_model.predict(X_test_scaled)\n",
    "ridge_predictions = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models on test set\n",
    "linear_reg_rmse = mean_squared_error(y_test, linear_reg_predictions) ** .5\n",
    "lasso_rmse = mean_squared_error(y_test, lasso_predictions) ** .5\n",
    "ridge_rmse = mean_squared_error(y_test, ridge_predictions) ** .5\n",
    "\n",
    "\n",
    "linear_reg_r2 = r2_score(y_test, linear_reg_predictions)\n",
    "lasso_r2 = r2_score(y_test, lasso_predictions)\n",
    "ridge_r2 = r2_score(y_test, ridge_predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Linear Regression (Test Set):\")\n",
    "print(\"RMSE:\", linear_reg_rmse)\n",
    "print(\"R-squared Score:\", linear_reg_r2)\n",
    "print()\n",
    "print(\"Lasso Regression (Test Set):\")\n",
    "print(\"RMSE:\", lasso_rmse)\n",
    "print(\"R-squared Score:\", lasso_r2)\n",
    "print()\n",
    "print(\"Ridge Regression (Test Set):\")\n",
    "print(\"RMSE:\", ridge_rmse)\n",
    "print(\"R-squared Score:\", ridge_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963e06f-79b6-4082-9586-efaf65cdacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2179db4-7a5a-4478-9b12-11bb18088419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on TRAINING set\n",
    "linear_reg_predictions = linear_reg_model.predict(X_train_scaled)\n",
    "lasso_predictions = lasso_model.predict(X_train_scaled)\n",
    "ridge_predictions = ridge_model.predict(X_train_scaled)\n",
    "\n",
    "# Evaluate on TRAINING set\n",
    "linear_reg_rmse = mean_squared_error(y_train, linear_reg_predictions) ** .5\n",
    "lasso_rmse = mean_squared_error(y_train, lasso_predictions) ** .5\n",
    "ridge_rmse = mean_squared_error(y_train, ridge_predictions) ** .5\n",
    "\n",
    "linear_reg_r2 = r2_score(y_train, linear_reg_predictions)\n",
    "lasso_r2 = r2_score(y_train, lasso_predictions)\n",
    "ridge_r2 = r2_score(y_train, ridge_predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Linear Regression: (Training Set)\")\n",
    "print(\"RMSE:\", linear_reg_rmse)\n",
    "print(\"R-squared Score:\", linear_reg_r2)\n",
    "print()\n",
    "print(\"Lasso Regression (Training Set):\")\n",
    "print(\"RMSE:\", lasso_rmse)\n",
    "print(\"R-squared Score:\", lasso_r2)\n",
    "print()\n",
    "print(\"Ridge Regression (Training Set):\")\n",
    "print(\"RMSE:\", ridge_rmse)\n",
    "print(\"R-squared Score:\", ridge_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf98124-1ec1-4f0e-98e6-f951d223d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc27a6-b539-4278-a2db-85931cb64688",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de009823-8124-4194-bd1b-ebb27e7d17e4",
   "metadata": {},
   "source": [
    "All three models, Linear Regression, Lasso Regression, and Ridge Regression, achieved similar performance in terms of RMSE and R-squared score, indicating they fit the training data well and explained around 84% of the variance in the target variable.\n",
    "\n",
    "Similarly, all models exhibit similar performance on the test set with slightly higher RMSE values and slightly lower R-squared scores compared to the training set. This suggests that the models generalize reasonably well to unseen data, though there is a slight drop in performance compared to the training set. Comparison:\n",
    "\n",
    "There is little difference in performance between Linear Regression, Lasso Regression, and Ridge Regression, with each method yielding comparable results. However, Ridge Regression slightly outperforms the other methods on the test set in terms of RMSE and R-squared score. Overall, the models provide a reasonable fit to the data, but there may be opportunities for further refinement or exploration of different modeling techniques to potentially improve predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d231eec0-7db7-4408-8107-fd8dd92bef3d",
   "metadata": {},
   "source": [
    "## Final Recommendations\n",
    "\n",
    "Assessing the value of a house is a challenging task, but I would recommend that buyers and sellers take into account the following factors. \n",
    "\n",
    "* The quality of materials that went into constructing the home\n",
    "* The square footage of the above ground living area\n",
    "* The amount of cars the garage can hold\n",
    "* The neighborhood the home is located in as well as the year the home was built"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f776ca-a822-4dea-b730-e513b33e0460",
   "metadata": {},
   "source": [
    "#### Creating Kaggle CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323528e3-bb15-4ac5-98b3-c2d228713709",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "final_columns = ['Overall Qual', 'Overall Cond', 'Year Built',\n",
    "       'Year Remod/Add', 'Mas Vnr Area', '1st Flr SF',\n",
    "       '2nd Flr SF', 'Gr Liv Area', 'Full Bath', 'Half Bath', 'Bedroom AbvGr',\n",
    "       'TotRms AbvGrd', 'Fireplaces', 'Garage Cars', 'Garage Area',\n",
    "       'Wood Deck SF', 'Open Porch SF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e599c-ec03-4303-9a25-c6b819d8c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = test3[final_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb17d9f-7bd0-4955-839f-7a8ee92d02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "final_test[numerical_features] = scaler.fit_transform(final_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ae111-09c4-40ab-8c06-8a0e1bf8e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test['SalePrice'] = linear_reg_model.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e98598-4b80-4087-9ed7-9e4f767c0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ab0ab-bdea-44f9-b38f-24910d9e1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test['Unnamed: 0'] = test3['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a02c11-6136-4803-a8c1-fc4cb73a957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test[['Unnamed: 0', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d9416-d6e4-4207-95e6-4b22d8d13736",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = final_test[['Unnamed: 0', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cb968-3d3b-4f4e-b756-58284e452342",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('KaggleSubmission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
